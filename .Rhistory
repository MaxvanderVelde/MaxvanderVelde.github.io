data$means[i]>data$upper[i]
data$means[i]<data$lower[i]
i= 1:100
data$means[i]>data$upper[i]
data$means[i]<data$lower[i]
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
set.seed(100)
samples<-replicate(100,rnorm(200,mean = 0,sd=1))
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
set.seed(100)
samples<-replicate(100,rnorm(200,mean = 0,sd=1))
View(samples)
# Step 2: Estimate statistics for the mean
# First the absolute bias(difference from the true mean)
means<-colMeans(samples)
means<-as.data.frame(means)
View(means)
quantile(samples)
min(samples)
quantile(samples[,1])
quantile(samples[,1],c(0.025,0.975))
# calculate standard error
# First the standart deviations
Standard_deviations<-apply(samples,2,(sd))
# then the standard errors
SE<-Standard_deviations/sqrt(200)
quantiles<-matrix(999,nrow =length(samples[1,]),ncol= 2 )
quantiles<-as.data.frame(quantiles)
for(i in 1:length(samples[1,])){
quantiles[i,]<-quantile(samples[,i],c(0.025,0.975))
}
colnames(quantiles)<-c("lower","upper")
data<-as.data.frame(cbind(means,quantiles))
data$bad<-0
for(i in 1:100){
if(data$means[i]>data$upper[i]|data$means[i]<data$lower[i])
data$bad[i]<-1
else{
data$bad[i]<-0
}
}
View(data)
# then the standard errors
SE<-1/sqrt(200)
# then the standard errors
SE<-1/sqrt(200)
quantiles<-matrix(999,nrow =length(samples[1,]),ncol= 2 )
quantiles<-as.data.frame(quantiles)
quantiles[i,]<-qt(samples[,i],c(0.025,0.975))
quantiles<-matrix(999,nrow =length(samples[1,]),ncol= 2 )
quantiles<-as.data.frame(quantiles)
for(i in 1:length(samples[1,])){
quantiles[i,]<-quantile(samples[,i],c(0.025,0.975))
}
colnames(quantiles)<-c("lower","upper")
data<-as.data.frame(cbind(means,quantiles))
data$bad<-0
View(data)
quantiles
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
set.seed(100)
samples<-replicate(100,rnorm(5000,mean = 0,sd=1))
# Step 2: Estimate statistics for the mean
# First the absolute bias(difference from the true mean)
means<-colMeans(samples)
means<-as.data.frame(means)
# Given that the actual mean is equal to zero, the following code provides the absolute error
abs(means)
# calculate standard error
# First the standart deviations
Standard_deviations<-apply(samples,2,(sd))
# then the standard errors
SE<-1/sqrt(200)
# then the standard errors
SE<-1/sqrt(5000)
quantiles<-matrix(999,nrow =length(samples[1,]),ncol= 2 )
quantiles<-as.data.frame(quantiles)
for(i in 1:length(samples[1,])){
quantiles[i,]<-quantile(samples[,i],c(0.025,0.975))
}
colnames(quantiles)<-c("lower","upper")
data<-as.data.frame(cbind(means,quantiles))
data$bad<-0
View(data)
?quantile
info <- function(x){
M <- mean(x)
DF <- length(x) - 1
SE <- 1 / sqrt(length(x))
INT <- qt(.975, DF) * SE
return(c(M, M - 0, SE, M - INT, M + INT))
}
info(samples)
bla<-info(samples)
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
set.seed(100)
samples<-replicate(100,rnorm(500,mean = 0,sd=1))
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
set.seed(100)
samples<-replicate(100,rnorm(500,mean = 0,sd=1))
# Step 2: Estimate statistics for the mean
# First the absolute bias(difference from the true mean)
means<-colMeans(samples)
means<-as.data.frame(means)
# Given that the actual mean is equal to zero, the following code provides the absolute error
abs(means)
# calculate standard error
# First the standart deviations
Standard_deviations<-apply(samples,2,(sd))
# then the standard errors
SE<-1/sqrt(5000)
results <- samples %>%
vapply(., info, format) %>%
t()
u
info <- function(x){
M <- mean(x)
DF <- length(x) - 1
SE <- 1 / sqrt(length(x))
INT <- qt(.975, DF) * SE
return(c(M, M - 0, SE, M - INT, M + INT))
}
bla<-info(samples)
results <- samples %>%
vapply(., info, format) %>%
t()
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
set.seed(100)
samples<-replicate(100,rnorm(500,mean = 0,sd=1))
apply(samples,2,mean)
means<-apply(samples,2,mean)
SE<-1/sqrt(5000)
SE<-1/sqrt(500)
# Confidence intervals
?qt
?qnorm
# Calculate intervals
# FIrst we need degrees of freedom
DF<-
interval<-qnorm(.975,mean=0,sd=1) * SE
# Calculate intervals
# FIrst we need degrees of freedom
interval<-qnorm(.975,mean=0,sd=1) * SE
# Calculate intervals
# FIrst we need degrees of freedom
interval<-qnorm(c(0.025,.975),mean=0,sd=1) * SE
# Calculate intervals
# FIrst we need degrees of freedom
interval<-qnorm(c(0.025,.975),mean=means,sd=1) * SE
interval
# Calculate intervals
# FIrst we need degrees of freedom
intervallow<-qnorm(0.025,mean=means,sd=1) * SE
intervalhigh<-qnorm(0.025,mean=means,sd=1) * SE
# Calculate intervals
# FIrst we need degrees of freedom
intervallow<-qnorm(0.025,mean=means,sd=1) * SE
intervalhigh<-qnorm(0.975,mean=means,sd=1) * SE
upperlimit<-means+intervalhigh
lowerlimit<-means+intervallow
data<-as.data.frame(cbind(means,lowerlimit,upperlimit))
View(data)
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
set.seed(100)
samples<-replicate(100,rnorm(5000,mean = 0,sd=1))
# Step 2: calculate error(the mean difference fom 0)
means<-apply(samples,2,mean)
# Calculate SE
SE<-1/sqrt(5000)
# Calculate intervals
# FIrst we need degrees of freedom
intervallow<-qnorm(0.025,mean=means,sd=1) * SE
intervalhigh<-qnorm(0.975,mean=means,sd=1) * SE
upperlimit<-means+intervalhigh
lowerlimit<-means+intervallow
data<-as.data.frame(cbind(means,lowerlimit,upperlimit))
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
set.seed(100)
samples<-replicate(100,rnorm(1000,mean = 0,sd=1))
# Step 2: calculate error(the mean difference fom 0)
means<-apply(samples,2,mean)
# Calculate SE
SE<-1/sqrt(5000)
# Calculate intervals
# FIrst we need degrees of freedom
intervallow<-qnorm(0.025,mean=means,sd=1) * SE
intervalhigh<-qnorm(0.975,mean=means,sd=1) * SE
upperlimit<-means+intervalhigh
lowerlimit<-means+intervallow
data<-as.data.frame(cbind(means,lowerlimit,upperlimit))
# Provide an indicator of whether the confidence interval include the true population mean
data$bad<-0
# Provide an indicator of whether the confidence interval include the true population mean
data$zeroinconf<-0 # Create some space
for( i in 1:data[,1]){
if(data$lowerlimit[i]<0 & data$upperlimit[i]>0){
data$zeroinconf[i]<-1
}else
data$zeroinconf[i]<-0
}
1:data[,1]
data[,1]
# Provide an indicator of whether the confidence interval include the true population mean
data$zeroinconf<-0 # Create some space
for( i in 1:length(data[,1])){
if(data$lowerlimit[i]<0 & data$upperlimit[i]>0){
data$zeroinconf[i]<-1
}else
data$zeroinconf[i]<-0
}
View(data)
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
library(tidyverse)
limits <- aes(ymax = data$upperlimit, ymin = data$lowerlimit)
View(limits)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2) +
geom_pointrange(limits) +
xlab("Simulations 1-100") +
ylab("Means and 95% Confidence Intervals")
limits <- aes(ymax = data$upperlimit, ymin = data$lowerlimit)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2) +
geom_pointrange(limits) +
xlab("Simulations 1-100") +
ylab("Means and 95% Confidence Intervals")
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf))
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2) +
geom_pointrange(limits)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2) +
geom_pointrange(limits) +
xlab("Simulations 1-100") +
ylab("Means and 95% Confidence Intervals")
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
library(tidyverse)
set.seed(100)
samples<-replicate(100,rnorm(10000,mean = 0,sd=1))
# Step 2: calculate error(the mean difference fom 0)
means<-apply(samples,2,mean)
# Calculate SE
SE<-1/sqrt(5000)
# Calculate intervals
# FIrst we need degrees of freedom
intervallow<-qnorm(0.025,mean=means,sd=1) * SE
intervalhigh<-qnorm(0.975,mean=means,sd=1) * SE
upperlimit<-means+intervalhigh
lowerlimit<-means+intervallow
# Place all this nice information in a single dataframe
data<-as.data.frame(cbind(means,lowerlimit,upperlimit))
# Provide an indicator of whether the confidence interval include the true population mean
data$zeroinconf<-0 # Create some space
for( i in 1:length(data[,1])){
if(data$lowerlimit[i]<0 & data$upperlimit[i]>0){
data$zeroinconf[i]<-1
}else
data$zeroinconf[i]<-0
}
limits <- aes(ymax = data$upperlimit, ymin = data$lowerlimit)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2) +
geom_pointrange(limits) +
xlab("Simulations 1-100") +
ylab("Means and 95% Confidence Intervals")
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
library(tidyverse)
set.seed(100)
samples<-replicate(100,rnorm(5000,mean = 0,sd=1))
# Step 2: calculate error(the mean difference fom 0)
means<-apply(samples,2,mean)
# Calculate SE
SE<-1/sqrt(5000)
# Calculate intervals
# FIrst we need degrees of freedom
intervallow<-qnorm(0.025,mean=means,sd=1) * SE
intervalhigh<-qnorm(0.975,mean=means,sd=1) * SE
upperlimit<-means+intervalhigh
lowerlimit<-means+intervallow
# Place all this nice information in a single dataframe
data<-as.data.frame(cbind(means,lowerlimit,upperlimit))
# Provide an indicator of whether the confidence interval include the true population mean
data$zeroinconf<-0 # Create some space
for( i in 1:length(data[,1])){
if(data$lowerlimit[i]<0 & data$upperlimit[i]>0){
data$zeroinconf[i]<-1
}else
data$zeroinconf[i]<-0
}
limits <- aes(ymax = data$upperlimit, ymin = data$lowerlimit)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2) +
geom_pointrange(limits) +
xlab("Simulations 1-100") +
ylab("Means and 95% Confidence Intervals")
samples<-replicate(100,rnorm(6000,mean = 0,sd=1))
# Step 2: calculate error(the mean difference fom 0)
means<-apply(samples,2,mean)
# Calculate SE
SE<-1/sqrt(5000)
# Calculate intervals
# FIrst we need degrees of freedom
intervallow<-qnorm(0.025,mean=means,sd=1) * SE
intervalhigh<-qnorm(0.975,mean=means,sd=1) * SE
upperlimit<-means+intervalhigh
lowerlimit<-means+intervallow
# Place all this nice information in a single dataframe
data<-as.data.frame(cbind(means,lowerlimit,upperlimit))
# Provide an indicator of whether the confidence interval include the true population mean
data$zeroinconf<-0 # Create some space
for( i in 1:length(data[,1])){
if(data$lowerlimit[i]<0 & data$upperlimit[i]>0){
data$zeroinconf[i]<-1
}else
data$zeroinconf[i]<-0
}
limits <- aes(ymax = data$upperlimit, ymin = data$lowerlimit)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2) +
geom_pointrange(limits) +
xlab("Simulations 1-100") +
ylab("Means and 95% Confidence Intervals")
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
library(tidyverse)
set.seed(100)
samples<-replicate(100,rnorm(4000,mean = 0,sd=1))
# Step 2: calculate error(the mean difference fom 0)
means<-apply(samples,2,mean)
# Calculate SE
SE<-1/sqrt(5000)
# Calculate intervals
# FIrst we need degrees of freedom
intervallow<-qnorm(0.025,mean=means,sd=1) * SE
intervalhigh<-qnorm(0.975,mean=means,sd=1) * SE
upperlimit<-means+intervalhigh
lowerlimit<-means+intervallow
# Place all this nice information in a single dataframe
data<-as.data.frame(cbind(means,lowerlimit,upperlimit))
# Provide an indicator of whether the confidence interval include the true population mean
data$zeroinconf<-0 # Create some space
for( i in 1:length(data[,1])){
if(data$lowerlimit[i]<0 & data$upperlimit[i]>0){
data$zeroinconf[i]<-1
}else
data$zeroinconf[i]<-0
}
limits <- aes(ymax = data$upperlimit, ymin = data$lowerlimit)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2) +
geom_pointrange(limits) +
xlab("Simulations 1-100") +
ylab("Means and 95% Confidence Intervals")
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
library(tidyverse)
set.seed(100)
samples<-replicate(100,rnorm(4500,mean = 0,sd=1))
# Step 2: calculate error(the mean difference fom 0)
means<-apply(samples,2,mean)
# Calculate SE
SE<-1/sqrt(5000)
# Calculate intervals
# FIrst we need degrees of freedom
intervallow<-qnorm(0.025,mean=means,sd=1) * SE
intervalhigh<-qnorm(0.975,mean=means,sd=1) * SE
upperlimit<-means+intervalhigh
lowerlimit<-means+intervallow
# Place all this nice information in a single dataframe
data<-as.data.frame(cbind(means,lowerlimit,upperlimit))
# Provide an indicator of whether the confidence interval include the true population mean
data$zeroinconf<-0 # Create some space
for( i in 1:length(data[,1])){
if(data$lowerlimit[i]<0 & data$upperlimit[i]>0){
data$zeroinconf[i]<-1
}else
data$zeroinconf[i]<-0
}
limits <- aes(ymax = data$upperlimit, ymin = data$lowerlimit)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2) +
geom_pointrange(limits) +
xlab("Simulations 1-100") +
ylab("Means and 95% Confidence Intervals")
# Monte carlo simulatie opdracht
# Step 1: simulate 100 samples, each containing 200 scores, drawn from the standard normal distibution
library(tidyverse)
set.seed(100)
samples<-replicate(100,rnorm(5000,mean = 0,sd=1))
# Step 2: calculate error(the mean difference fom 0)
means<-apply(samples,2,mean)
# Calculate SE
SE<-1/sqrt(5000)
# Calculate intervals
# FIrst we need degrees of freedom
intervallow<-qnorm(0.025,mean=means,sd=1) * SE
intervalhigh<-qnorm(0.975,mean=means,sd=1) * SE
upperlimit<-means+intervalhigh
lowerlimit<-means+intervallow
# Place all this nice information in a single dataframe
data<-as.data.frame(cbind(means,lowerlimit,upperlimit))
# Provide an indicator of whether the confidence interval include the true population mean
data$zeroinconf<-0 # Create some space
for( i in 1:length(data[,1])){
if(data$lowerlimit[i]<0 & data$upperlimit[i]>0){
data$zeroinconf[i]<-1
}else
data$zeroinconf[i]<-0
}
limits <- aes(ymax = data$upperlimit, ymin = data$lowerlimit)
ggplot(data, aes(y=means, x=1:100, colour = zeroinconf)) +
geom_hline(aes(yintercept = 0), color = "dark grey", size = 2) +
geom_pointrange(limits) +
xlab("Simulations 1-100") +
ylab("Means and 95% Confidence Intervals")
table(data[data$zeroinconf==0])
data[data$zeroinconf==0]
data[,data$zeroinconf==0]
?kable
dat<-data[data$zeroinconf==0]]
dat<-data[data$zeroinconf==0]
dat<-data%>%
filter(zeroinconf==0)
View(dat)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
bla1<-5
bla2<-6
bla3<-7
bla4<-8
bla1
set.seed(100)
numbers<-rnorm(100,2,1)
set.seed(100)
numbers<-rnorm(100,2,1)
mean(numbers)
Output<-mean(numbers)
replications<-replicate(10,rnorm(100,2,1))
View(replications)
Outputs<-colMeans(replications)
set.seed(100)
numbers2<-rnorm(100,2,1)
Output2<-mean(numbers)
set.seed(100)
numbers2<-rnorm(100,2,1)
Output2<-mean(numbers)
---
title: "Assignment2_max"
author: "max"
date: "10/21/2020"
output: html_document
---
# Step 1: Do somthing that has some RNG elements to  and produces output
```{r echo=TRUE}
set.seed(100)
numbers2<-rnorm(100,2,1)
Output2<-mean(numbers)
```
# Step 2: Replicate the results 10 times
```{r}
replications2<-replicate(10,rnorm(100,2,1))
Outputs2<-colMeans(replications)
plot(Outputs)
plot(Outputs)
points(Output,col="red")
plot(Outputs)
points(Output,col="red")
hist(Outputs)
points(Output,col="red")
hist(Outputs)
points(Output,col="red")
hist(Outputs)
line(Output,col="red")
hist(Outputs)
abline(Output,col="red")
hist(Outputs)
abline(v=Output,col="red")
Outputs
boxplot(Outputs,xlab = "Hopelijk hebt u een prettig weekend(Of een prettige weekdag, indien het geen weekend is)")
points(Output,col="red")
boxplot(Outputs,xlab = "Hopelijk hebt u een prettig weekend(Of een prettige weekdag, indien het geen weekend is)")
lines(Output,col="red")
boxplot(Outputs,xlab = "Hopelijk hebt u een prettig weekend(Of een prettige weekdag, indien het geen weekend is)")
abline(Output,col="red")
boxplot(Outputs,xlab = "Hopelijk hebt u een prettig weekend(Of een prettige weekdag, indien het geen weekend is)")
points(Output,col="red")
replications<-replicate(10,rnorm(100,2,1))
View(replications2)
sessioninfo()
sessioninfo()
sessionInfo()
install.packages("reprex")
ab<-2*2
library(reprex)
reprex()
setwd("~/")
setwd("~/GitHub/MaxvanderVelde.github.io")
